{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate 10 synthetic datasets where the number of datapoints should vary from 100 to 1000 by step size 100. With 100 features in each dataset. In that 100 features 40 should be informative.\n",
    "\n",
    "#### a. Implement Linear Regression on each generated synthetic datasets and find Mean Square Error(MSE).\n",
    "Note : Write down your observation on how MSE changes with increasing in dataset size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points_lengths = [x for x in range(100,1001,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_points_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 100 data points\n",
      "Mean squared error:  4.455521733656828e-25\n",
      "\n",
      "Dataset with 200 data points\n",
      "Mean squared error:  7.181581421853113e-25\n",
      "\n",
      "Dataset with 300 data points\n",
      "Mean squared error:  8.659663578715574e-25\n",
      "\n",
      "Dataset with 400 data points\n",
      "Mean squared error:  5.568180379301029e-25\n",
      "\n",
      "Dataset with 500 data points\n",
      "Mean squared error:  5.760528649365431e-25\n",
      "\n",
      "Dataset with 600 data points\n",
      "Mean squared error:  7.18252416404731e-25\n",
      "\n",
      "Dataset with 700 data points\n",
      "Mean squared error:  5.970665868075864e-25\n",
      "\n",
      "Dataset with 800 data points\n",
      "Mean squared error:  5.106911635457319e-25\n",
      "\n",
      "Dataset with 900 data points\n",
      "Mean squared error:  9.287086518856548e-25\n",
      "\n",
      "Dataset with 1000 data points\n",
      "Mean squared error:  7.340148253548543e-25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_points in data_points_lengths:\n",
    "    x,y = datasets.make_regression(n_samples=data_points, n_features=100, n_informative=40) \n",
    "    \n",
    "    # Model initialization\n",
    "    regression_model = LinearRegression()\n",
    "    # Fit the data(train the model)\n",
    "    regression_model.fit(x, y)\n",
    "    # Predict\n",
    "    y_predicted = regression_model.predict(x)\n",
    "\n",
    "    # model evaluation\n",
    "    mse = mean_squared_error(y, y_predicted)\n",
    "    r2 = r2_score(y, y_predicted)\n",
    "\n",
    "    # printing values\n",
    "    print(f\"Dataset with {data_points} data points\")\n",
    "    print('Mean squared error: ', mse)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "         For less number of data points(100),the mean squared error is less compared to others.In some cases,mean squared error increased with increase in number of datapoints.But "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate a synthetic dataset with 100 features and 1000 data points. In that 100 features 40 should be informative. Retrieve the Important features on generated synthetic dataset using Linear Regression Features Importance technique.\n",
    "\n",
    "#### a. Implement Linear Regression on the retrieved important features and find the Mean Square Error(MSE).\n",
    "\n",
    "#### b. Implement Ridge Regression on the retrieved important features and find the Mean Square Error(MSE).\n",
    "\n",
    "#### c. Implement Lasso Regression on the retrieved important features and find the Mean Square Error(MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.037457</td>\n",
       "      <td>-0.443525</td>\n",
       "      <td>0.106271</td>\n",
       "      <td>-0.482758</td>\n",
       "      <td>0.265839</td>\n",
       "      <td>0.317130</td>\n",
       "      <td>-1.768247</td>\n",
       "      <td>-0.920706</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>-1.531007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320548</td>\n",
       "      <td>1.367012</td>\n",
       "      <td>-0.795555</td>\n",
       "      <td>-0.947806</td>\n",
       "      <td>1.149068</td>\n",
       "      <td>1.234440</td>\n",
       "      <td>-0.227630</td>\n",
       "      <td>1.366145</td>\n",
       "      <td>-0.854670</td>\n",
       "      <td>-0.124365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.347416</td>\n",
       "      <td>0.644452</td>\n",
       "      <td>-1.510793</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>-1.954802</td>\n",
       "      <td>0.108687</td>\n",
       "      <td>2.153033</td>\n",
       "      <td>0.353528</td>\n",
       "      <td>0.178070</td>\n",
       "      <td>0.585245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738040</td>\n",
       "      <td>-0.368258</td>\n",
       "      <td>1.792738</td>\n",
       "      <td>-1.543363</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.063517</td>\n",
       "      <td>-0.437428</td>\n",
       "      <td>-0.360336</td>\n",
       "      <td>-0.037996</td>\n",
       "      <td>-0.348957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536981</td>\n",
       "      <td>1.205548</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>-0.568484</td>\n",
       "      <td>1.038975</td>\n",
       "      <td>2.025406</td>\n",
       "      <td>0.201018</td>\n",
       "      <td>0.214859</td>\n",
       "      <td>-0.368834</td>\n",
       "      <td>1.672440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024898</td>\n",
       "      <td>-0.578313</td>\n",
       "      <td>-0.543815</td>\n",
       "      <td>-1.768620</td>\n",
       "      <td>-1.295388</td>\n",
       "      <td>-1.912383</td>\n",
       "      <td>0.866019</td>\n",
       "      <td>-0.216421</td>\n",
       "      <td>-0.511404</td>\n",
       "      <td>0.406439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.530326</td>\n",
       "      <td>-0.599941</td>\n",
       "      <td>0.171904</td>\n",
       "      <td>-0.369584</td>\n",
       "      <td>0.158248</td>\n",
       "      <td>-2.384047</td>\n",
       "      <td>-1.011385</td>\n",
       "      <td>-0.858778</td>\n",
       "      <td>1.232906</td>\n",
       "      <td>-0.115778</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.080653</td>\n",
       "      <td>0.193297</td>\n",
       "      <td>2.028831</td>\n",
       "      <td>-1.021008</td>\n",
       "      <td>0.228192</td>\n",
       "      <td>0.640286</td>\n",
       "      <td>-1.050733</td>\n",
       "      <td>0.945450</td>\n",
       "      <td>0.813038</td>\n",
       "      <td>-1.378401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.808723</td>\n",
       "      <td>-0.855514</td>\n",
       "      <td>0.208099</td>\n",
       "      <td>1.534268</td>\n",
       "      <td>-0.273883</td>\n",
       "      <td>1.728550</td>\n",
       "      <td>0.304369</td>\n",
       "      <td>-0.266382</td>\n",
       "      <td>-0.139389</td>\n",
       "      <td>-0.587248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263951</td>\n",
       "      <td>1.108451</td>\n",
       "      <td>0.735835</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>0.875822</td>\n",
       "      <td>0.021737</td>\n",
       "      <td>-0.548799</td>\n",
       "      <td>0.083899</td>\n",
       "      <td>-0.354407</td>\n",
       "      <td>0.630328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.966117</td>\n",
       "      <td>-0.531451</td>\n",
       "      <td>-0.197657</td>\n",
       "      <td>0.090548</td>\n",
       "      <td>-1.228518</td>\n",
       "      <td>-1.877118</td>\n",
       "      <td>-1.070386</td>\n",
       "      <td>0.302919</td>\n",
       "      <td>-0.419963</td>\n",
       "      <td>1.916052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.666901</td>\n",
       "      <td>0.924126</td>\n",
       "      <td>0.298555</td>\n",
       "      <td>-0.490056</td>\n",
       "      <td>-1.155669</td>\n",
       "      <td>-1.981226</td>\n",
       "      <td>0.407989</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.688677</td>\n",
       "      <td>0.348060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.410075</td>\n",
       "      <td>0.445049</td>\n",
       "      <td>1.352905</td>\n",
       "      <td>1.340598</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-1.413404</td>\n",
       "      <td>-0.668911</td>\n",
       "      <td>0.840563</td>\n",
       "      <td>0.748414</td>\n",
       "      <td>0.376247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.165829</td>\n",
       "      <td>1.754117</td>\n",
       "      <td>-0.256790</td>\n",
       "      <td>0.354718</td>\n",
       "      <td>-1.151848</td>\n",
       "      <td>0.090762</td>\n",
       "      <td>0.246572</td>\n",
       "      <td>-2.024328</td>\n",
       "      <td>-0.420456</td>\n",
       "      <td>-0.724892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.097766</td>\n",
       "      <td>-0.390900</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>-1.091450</td>\n",
       "      <td>0.868239</td>\n",
       "      <td>-1.571157</td>\n",
       "      <td>-0.423502</td>\n",
       "      <td>0.544585</td>\n",
       "      <td>0.332266</td>\n",
       "      <td>1.100469</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.224407</td>\n",
       "      <td>1.190104</td>\n",
       "      <td>-0.959499</td>\n",
       "      <td>-1.029171</td>\n",
       "      <td>0.503232</td>\n",
       "      <td>-0.103767</td>\n",
       "      <td>-1.030098</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>-0.527911</td>\n",
       "      <td>0.285215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.290002</td>\n",
       "      <td>-2.816527</td>\n",
       "      <td>-0.300776</td>\n",
       "      <td>1.875994</td>\n",
       "      <td>0.161660</td>\n",
       "      <td>-0.749914</td>\n",
       "      <td>-1.218460</td>\n",
       "      <td>0.496001</td>\n",
       "      <td>0.404165</td>\n",
       "      <td>-1.141416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967568</td>\n",
       "      <td>-1.450607</td>\n",
       "      <td>0.383195</td>\n",
       "      <td>0.519604</td>\n",
       "      <td>1.366608</td>\n",
       "      <td>-0.765856</td>\n",
       "      <td>-1.419972</td>\n",
       "      <td>1.185495</td>\n",
       "      <td>-0.531591</td>\n",
       "      <td>-0.254360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.644098</td>\n",
       "      <td>-0.872105</td>\n",
       "      <td>0.968400</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.629644</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>0.382501</td>\n",
       "      <td>0.026289</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.112118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489621</td>\n",
       "      <td>1.215758</td>\n",
       "      <td>-0.240090</td>\n",
       "      <td>-0.667939</td>\n",
       "      <td>0.069135</td>\n",
       "      <td>-0.656678</td>\n",
       "      <td>-0.072182</td>\n",
       "      <td>-1.053525</td>\n",
       "      <td>1.115121</td>\n",
       "      <td>0.424239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -1.037457 -0.443525  0.106271 -0.482758  0.265839  0.317130 -1.768247   \n",
       "1    0.347416  0.644452 -1.510793  0.035012 -1.954802  0.108687  2.153033   \n",
       "2    0.536981  1.205548  0.279899 -0.568484  1.038975  2.025406  0.201018   \n",
       "3   -1.530326 -0.599941  0.171904 -0.369584  0.158248 -2.384047 -1.011385   \n",
       "4    0.808723 -0.855514  0.208099  1.534268 -0.273883  1.728550  0.304369   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -1.966117 -0.531451 -0.197657  0.090548 -1.228518 -1.877118 -1.070386   \n",
       "996  0.410075  0.445049  1.352905  1.340598 -0.114959 -1.413404 -0.668911   \n",
       "997 -0.097766 -0.390900  0.947578 -1.091450  0.868239 -1.571157 -0.423502   \n",
       "998 -0.290002 -2.816527 -0.300776  1.875994  0.161660 -0.749914 -1.218460   \n",
       "999 -0.644098 -0.872105  0.968400  0.036187  0.629644 -0.601060  0.382501   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0   -0.920706  0.966119 -1.531007  ... -0.320548  1.367012 -0.795555   \n",
       "1    0.353528  0.178070  0.585245  ...  0.738040 -0.368258  1.792738   \n",
       "2    0.214859 -0.368834  1.672440  ... -0.024898 -0.578313 -0.543815   \n",
       "3   -0.858778  1.232906 -0.115778  ... -1.080653  0.193297  2.028831   \n",
       "4   -0.266382 -0.139389 -0.587248  ...  0.263951  1.108451  0.735835   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.302919 -0.419963  1.916052  ... -0.666901  0.924126  0.298555   \n",
       "996  0.840563  0.748414  0.376247  ... -1.165829  1.754117 -0.256790   \n",
       "997  0.544585  0.332266  1.100469  ... -1.224407  1.190104 -0.959499   \n",
       "998  0.496001  0.404165 -1.141416  ...  0.967568 -1.450607  0.383195   \n",
       "999  0.026289 -0.001357 -0.112118  ...  0.489621  1.215758 -0.240090   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0   -0.947806  1.149068  1.234440 -0.227630  1.366145 -0.854670 -0.124365  \n",
       "1   -1.543363  0.685649  0.063517 -0.437428 -0.360336 -0.037996 -0.348957  \n",
       "2   -1.768620 -1.295388 -1.912383  0.866019 -0.216421 -0.511404  0.406439  \n",
       "3   -1.021008  0.228192  0.640286 -1.050733  0.945450  0.813038 -1.378401  \n",
       "4   -0.556132  0.875822  0.021737 -0.548799  0.083899 -0.354407  0.630328  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.490056 -1.155669 -1.981226  0.407989 -0.000252  0.688677  0.348060  \n",
       "996  0.354718 -1.151848  0.090762  0.246572 -2.024328 -0.420456 -0.724892  \n",
       "997 -1.029171  0.503232 -0.103767 -1.030098  0.185299 -0.527911  0.285215  \n",
       "998  0.519604  1.366608 -0.765856 -1.419972  1.185495 -0.531591 -0.254360  \n",
       "999 -0.667939  0.069135 -0.656678 -0.072182 -1.053525  1.115121  0.424239  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define dataset\n",
    "x,y = datasets.make_regression(n_samples=1000, n_features=100, n_informative=40)\n",
    "x = pd.DataFrame(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 77.06575\n",
      "Feature: 1, Score: 16.90896\n",
      "Feature: 2, Score: 9.97598\n",
      "Feature: 3, Score: 28.16567\n",
      "Feature: 4, Score: 59.62499\n",
      "Feature: 5, Score: 62.17143\n",
      "Feature: 6, Score: 10.40414\n",
      "Feature: 7, Score: 80.02321\n",
      "Feature: 8, Score: 97.53820\n",
      "Feature: 9, Score: 91.63643\n",
      "Feature: 10, Score: 25.08120\n",
      "Feature: 11, Score: 23.41390\n",
      "Feature: 12, Score: 84.05700\n",
      "Feature: 13, Score: 19.36466\n",
      "Feature: 14, Score: 29.95986\n",
      "Feature: 15, Score: 10.19245\n",
      "Feature: 16, Score: 17.83962\n",
      "Feature: 17, Score: 26.46006\n",
      "Feature: 18, Score: 37.37172\n",
      "Feature: 19, Score: 31.07222\n",
      "Feature: 20, Score: 5.99115\n",
      "Feature: 21, Score: 49.88202\n",
      "Feature: 22, Score: 39.11423\n",
      "Feature: 23, Score: 95.19192\n",
      "Feature: 24, Score: 31.79342\n",
      "Feature: 25, Score: 47.25502\n",
      "Feature: 26, Score: 74.91016\n",
      "Feature: 27, Score: 73.81113\n",
      "Feature: 28, Score: 62.62154\n",
      "Feature: 29, Score: 61.87862\n",
      "Feature: 30, Score: 55.78815\n",
      "Feature: 31, Score: 49.66495\n",
      "Feature: 32, Score: 66.37706\n",
      "Feature: 33, Score: 86.09665\n",
      "Feature: 34, Score: 54.35373\n",
      "Feature: 35, Score: 76.98452\n",
      "Feature: 36, Score: 88.25580\n",
      "Feature: 37, Score: 8.50823\n",
      "Feature: 38, Score: 21.09291\n",
      "Feature: 39, Score: 23.37973\n",
      "Feature: 40, Score: 76.04704\n",
      "Feature: 41, Score: 50.81097\n",
      "Feature: 42, Score: 25.28404\n",
      "Feature: 43, Score: 88.46820\n",
      "Feature: 44, Score: 38.46410\n",
      "Feature: 45, Score: 12.62104\n",
      "Feature: 46, Score: 50.28637\n",
      "Feature: 47, Score: 73.40512\n",
      "Feature: 48, Score: 92.21076\n",
      "Feature: 49, Score: 64.92136\n",
      "Feature: 50, Score: 8.70723\n",
      "Feature: 51, Score: 53.26678\n",
      "Feature: 52, Score: 59.61359\n",
      "Feature: 53, Score: 83.44440\n",
      "Feature: 54, Score: 76.10452\n",
      "Feature: 55, Score: 81.48649\n",
      "Feature: 56, Score: 69.30066\n",
      "Feature: 57, Score: 75.42824\n",
      "Feature: 58, Score: 12.35242\n",
      "Feature: 59, Score: 55.69803\n",
      "Feature: 60, Score: 64.47663\n",
      "Feature: 61, Score: 73.72959\n",
      "Feature: 62, Score: 67.70047\n",
      "Feature: 63, Score: 76.00429\n",
      "Feature: 64, Score: 43.58467\n",
      "Feature: 65, Score: 4.23993\n",
      "Feature: 66, Score: 79.02143\n",
      "Feature: 67, Score: 59.89430\n",
      "Feature: 68, Score: 26.40771\n",
      "Feature: 69, Score: 48.87772\n",
      "Feature: 70, Score: 85.04596\n",
      "Feature: 71, Score: 85.76396\n",
      "Feature: 72, Score: 52.59790\n",
      "Feature: 73, Score: 42.52021\n",
      "Feature: 74, Score: 20.06619\n",
      "Feature: 75, Score: 62.12930\n",
      "Feature: 76, Score: 45.10522\n",
      "Feature: 77, Score: 96.79272\n",
      "Feature: 78, Score: 10.22595\n",
      "Feature: 79, Score: 88.78164\n",
      "Feature: 80, Score: 37.95546\n",
      "Feature: 81, Score: 12.11259\n",
      "Feature: 82, Score: 3.53526\n",
      "Feature: 83, Score: 97.93900\n",
      "Feature: 84, Score: 26.33198\n",
      "Feature: 85, Score: 16.85653\n",
      "Feature: 86, Score: 7.85666\n",
      "Feature: 87, Score: 58.79940\n",
      "Feature: 88, Score: 56.44957\n",
      "Feature: 89, Score: 31.32722\n",
      "Feature: 90, Score: 36.46277\n",
      "Feature: 91, Score: 34.19101\n",
      "Feature: 92, Score: 22.65087\n",
      "Feature: 93, Score: 0.46514\n",
      "Feature: 94, Score: 77.30603\n",
      "Feature: 95, Score: 72.57292\n",
      "Feature: 96, Score: 42.39839\n",
      "Feature: 97, Score: 65.09345\n",
      "Feature: 98, Score: 99.34934\n",
      "Feature: 99, Score: 13.39405\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing features having importance < 0   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(x, y)\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "features_to_remove = []\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    if v > 0:\n",
    "        features_to_remove.append(i)\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()\n",
    "print(\"Removing features having importance < 0  \", features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>29</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>94</th>\n",
       "      <th>96</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.037457</td>\n",
       "      <td>0.265839</td>\n",
       "      <td>0.317130</td>\n",
       "      <td>0.117456</td>\n",
       "      <td>-0.221877</td>\n",
       "      <td>0.530065</td>\n",
       "      <td>0.520092</td>\n",
       "      <td>0.267789</td>\n",
       "      <td>-0.533157</td>\n",
       "      <td>-0.600266</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.949528</td>\n",
       "      <td>-0.596801</td>\n",
       "      <td>-0.230922</td>\n",
       "      <td>-1.278361</td>\n",
       "      <td>1.395075</td>\n",
       "      <td>0.433075</td>\n",
       "      <td>1.149068</td>\n",
       "      <td>-0.227630</td>\n",
       "      <td>-0.854670</td>\n",
       "      <td>-0.124365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.347416</td>\n",
       "      <td>-1.954802</td>\n",
       "      <td>0.108687</td>\n",
       "      <td>-0.470874</td>\n",
       "      <td>-1.861087</td>\n",
       "      <td>0.618662</td>\n",
       "      <td>-1.039640</td>\n",
       "      <td>0.966430</td>\n",
       "      <td>-0.015325</td>\n",
       "      <td>0.720279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323909</td>\n",
       "      <td>-1.044932</td>\n",
       "      <td>0.108029</td>\n",
       "      <td>2.388716</td>\n",
       "      <td>-0.723539</td>\n",
       "      <td>0.219113</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>-0.437428</td>\n",
       "      <td>-0.037996</td>\n",
       "      <td>-0.348957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536981</td>\n",
       "      <td>1.038975</td>\n",
       "      <td>2.025406</td>\n",
       "      <td>0.871397</td>\n",
       "      <td>-0.635038</td>\n",
       "      <td>-0.071576</td>\n",
       "      <td>1.592211</td>\n",
       "      <td>0.307040</td>\n",
       "      <td>-2.281987</td>\n",
       "      <td>-1.019408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611249</td>\n",
       "      <td>0.083040</td>\n",
       "      <td>-0.255114</td>\n",
       "      <td>-2.043266</td>\n",
       "      <td>-0.181508</td>\n",
       "      <td>1.377686</td>\n",
       "      <td>-1.295388</td>\n",
       "      <td>0.866019</td>\n",
       "      <td>-0.511404</td>\n",
       "      <td>0.406439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.530326</td>\n",
       "      <td>0.158248</td>\n",
       "      <td>-2.384047</td>\n",
       "      <td>0.545646</td>\n",
       "      <td>1.160552</td>\n",
       "      <td>-1.110194</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.216741</td>\n",
       "      <td>-0.196372</td>\n",
       "      <td>-0.058508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132040</td>\n",
       "      <td>-0.015277</td>\n",
       "      <td>1.118801</td>\n",
       "      <td>1.126133</td>\n",
       "      <td>-0.321185</td>\n",
       "      <td>0.244654</td>\n",
       "      <td>0.228192</td>\n",
       "      <td>-1.050733</td>\n",
       "      <td>0.813038</td>\n",
       "      <td>-1.378401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.808723</td>\n",
       "      <td>-0.273883</td>\n",
       "      <td>1.728550</td>\n",
       "      <td>-0.887171</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.698252</td>\n",
       "      <td>1.780900</td>\n",
       "      <td>0.300951</td>\n",
       "      <td>-0.528612</td>\n",
       "      <td>0.841673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274453</td>\n",
       "      <td>-0.794462</td>\n",
       "      <td>-0.447608</td>\n",
       "      <td>-0.610615</td>\n",
       "      <td>-0.408291</td>\n",
       "      <td>-1.143259</td>\n",
       "      <td>0.875822</td>\n",
       "      <td>-0.548799</td>\n",
       "      <td>-0.354407</td>\n",
       "      <td>0.630328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.966117</td>\n",
       "      <td>-1.228518</td>\n",
       "      <td>-1.877118</td>\n",
       "      <td>-0.646230</td>\n",
       "      <td>-0.182108</td>\n",
       "      <td>1.554613</td>\n",
       "      <td>0.671073</td>\n",
       "      <td>0.357890</td>\n",
       "      <td>1.097498</td>\n",
       "      <td>0.558496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345143</td>\n",
       "      <td>0.461356</td>\n",
       "      <td>0.753854</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>0.443871</td>\n",
       "      <td>-0.781740</td>\n",
       "      <td>-1.155669</td>\n",
       "      <td>0.407989</td>\n",
       "      <td>0.688677</td>\n",
       "      <td>0.348060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.410075</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-1.413404</td>\n",
       "      <td>-1.731649</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>-0.216861</td>\n",
       "      <td>-0.636763</td>\n",
       "      <td>-0.469556</td>\n",
       "      <td>-1.887726</td>\n",
       "      <td>0.446614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.620513</td>\n",
       "      <td>-1.065684</td>\n",
       "      <td>-1.049153</td>\n",
       "      <td>1.057495</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>1.266848</td>\n",
       "      <td>-1.151848</td>\n",
       "      <td>0.246572</td>\n",
       "      <td>-0.420456</td>\n",
       "      <td>-0.724892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.097766</td>\n",
       "      <td>0.868239</td>\n",
       "      <td>-1.571157</td>\n",
       "      <td>0.417344</td>\n",
       "      <td>-1.279733</td>\n",
       "      <td>1.569538</td>\n",
       "      <td>0.616420</td>\n",
       "      <td>0.121133</td>\n",
       "      <td>-1.500184</td>\n",
       "      <td>1.284546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865238</td>\n",
       "      <td>0.579284</td>\n",
       "      <td>0.941679</td>\n",
       "      <td>-0.038772</td>\n",
       "      <td>-0.512465</td>\n",
       "      <td>2.231031</td>\n",
       "      <td>0.503232</td>\n",
       "      <td>-1.030098</td>\n",
       "      <td>-0.527911</td>\n",
       "      <td>0.285215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.290002</td>\n",
       "      <td>0.161660</td>\n",
       "      <td>-0.749914</td>\n",
       "      <td>1.044849</td>\n",
       "      <td>0.131733</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.211246</td>\n",
       "      <td>0.725201</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>-0.626719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094066</td>\n",
       "      <td>0.505310</td>\n",
       "      <td>-0.485759</td>\n",
       "      <td>-2.409622</td>\n",
       "      <td>-1.049730</td>\n",
       "      <td>-0.537706</td>\n",
       "      <td>1.366608</td>\n",
       "      <td>-1.419972</td>\n",
       "      <td>-0.531591</td>\n",
       "      <td>-0.254360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.644098</td>\n",
       "      <td>0.629644</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>-0.126230</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>-1.253446</td>\n",
       "      <td>-1.059040</td>\n",
       "      <td>1.407759</td>\n",
       "      <td>-0.609096</td>\n",
       "      <td>0.961869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914252</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>1.296064</td>\n",
       "      <td>-1.178325</td>\n",
       "      <td>0.553250</td>\n",
       "      <td>-0.237861</td>\n",
       "      <td>0.069135</td>\n",
       "      <td>-0.072182</td>\n",
       "      <td>1.115121</td>\n",
       "      <td>0.424239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         4         5         12        16        20        25  \\\n",
       "0   -1.037457  0.265839  0.317130  0.117456 -0.221877  0.530065  0.520092   \n",
       "1    0.347416 -1.954802  0.108687 -0.470874 -1.861087  0.618662 -1.039640   \n",
       "2    0.536981  1.038975  2.025406  0.871397 -0.635038 -0.071576  1.592211   \n",
       "3   -1.530326  0.158248 -2.384047  0.545646  1.160552 -1.110194  0.216283   \n",
       "4    0.808723 -0.273883  1.728550 -0.887171  0.029859  0.698252  1.780900   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -1.966117 -1.228518 -1.877118 -0.646230 -0.182108  1.554613  0.671073   \n",
       "996  0.410075 -0.114959 -1.413404 -1.731649  0.877397 -0.216861 -0.636763   \n",
       "997 -0.097766  0.868239 -1.571157  0.417344 -1.279733  1.569538  0.616420   \n",
       "998 -0.290002  0.161660 -0.749914  1.044849  0.131733  0.035849  0.211246   \n",
       "999 -0.644098  0.629644 -0.601060 -0.126230  0.540490 -1.253446 -1.059040   \n",
       "\n",
       "           26        27        29  ...        70        72        74  \\\n",
       "0    0.267789 -0.533157 -0.600266  ... -1.949528 -0.596801 -0.230922   \n",
       "1    0.966430 -0.015325  0.720279  ... -0.323909 -1.044932  0.108029   \n",
       "2    0.307040 -2.281987 -1.019408  ... -0.611249  0.083040 -0.255114   \n",
       "3    0.216741 -0.196372 -0.058508  ... -1.132040 -0.015277  1.118801   \n",
       "4    0.300951 -0.528612  0.841673  ... -0.274453 -0.794462 -0.447608   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.357890  1.097498  0.558496  ...  0.345143  0.461356  0.753854   \n",
       "996 -0.469556 -1.887726  0.446614  ... -0.620513 -1.065684 -1.049153   \n",
       "997  0.121133 -1.500184  1.284546  ...  1.865238  0.579284  0.941679   \n",
       "998  0.725201 -0.184969 -0.626719  ...  0.094066  0.505310 -0.485759   \n",
       "999  1.407759 -0.609096  0.961869  ...  0.914252  0.191962  1.296064   \n",
       "\n",
       "           78        79        80        94        96        98        99  \n",
       "0   -1.278361  1.395075  0.433075  1.149068 -0.227630 -0.854670 -0.124365  \n",
       "1    2.388716 -0.723539  0.219113  0.685649 -0.437428 -0.037996 -0.348957  \n",
       "2   -2.043266 -0.181508  1.377686 -1.295388  0.866019 -0.511404  0.406439  \n",
       "3    1.126133 -0.321185  0.244654  0.228192 -1.050733  0.813038 -1.378401  \n",
       "4   -0.610615 -0.408291 -1.143259  0.875822 -0.548799 -0.354407  0.630328  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.235168  0.443871 -0.781740 -1.155669  0.407989  0.688677  0.348060  \n",
       "996  1.057495 -0.673409  1.266848 -1.151848  0.246572 -0.420456 -0.724892  \n",
       "997 -0.038772 -0.512465  2.231031  0.503232 -1.030098 -0.527911  0.285215  \n",
       "998 -2.409622 -1.049730 -0.537706  1.366608 -1.419972 -0.531591 -0.254360  \n",
       "999 -1.178325  0.553250 -0.237861  0.069135 -0.072182  1.115121  0.424239  \n",
       "\n",
       "[1000 rows x 34 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keeping important features\n",
    "x = x.drop(x.columns[features_to_remove], axis=1) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Coefficients :  -0.6367051473918222 13.120402044454014\n",
      "Mean squared error:  128914.80686032589\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "regression_model = LinearRegression()\n",
    "# Fit the data(train the model)\n",
    "regression_model.fit(x, y)\n",
    "# Predict\n",
    "y_predicted = regression_model.predict(x)\n",
    "# model evaluation\n",
    "mse = mean_squared_error(y, y_predicted)\n",
    "r2 = r2_score(y, y_predicted)\n",
    "\n",
    "# printing values\n",
    "print(\"Linear Regression\")\n",
    "print(\"Coefficients : \",regression_model.coef_[0],regression_model.intercept_)\n",
    "print('Mean squared error: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: [ -0.6367862    2.03098281  -4.07815253  15.47256985   6.11299406\n",
      "  -4.56605918   9.21197202   6.59510419   4.39383498   7.79952723\n",
      "   1.8481052  -15.54043535  -7.56741863  -3.01753209 -11.67461363\n",
      "  -8.18702215   2.2483448   -0.19258541  26.26859212 -12.55652584\n",
      "   0.98914188   7.27264389  30.56084528  -7.77558521  10.90112654\n",
      "  16.72014107 -10.25112252  -1.72794239   5.43748728  -2.64272736\n",
      "  12.4506675  -10.1192281  -15.22693475 -11.47331036]\n",
      "Intercept: 13.119225895126618\n",
      " Mean squared error:  128914.81129061665\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Ridge(alpha=1.0)\n",
    "# fit model\n",
    "model.fit(x, y)\n",
    "\n",
    "y_predicted = model.predict(x)\n",
    "\n",
    "# model evaluation\n",
    "mse = mean_squared_error(y, y_predicted)\n",
    "r2 = r2_score(y, y_predicted)\n",
    "\n",
    "# printing values\n",
    "print(\"Ridge Regression\")\n",
    "print('Slope:' ,model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "print(' Mean squared error: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression\n",
      "Slope: [ -0.           1.0554985   -3.31590948  14.25370638   5.47139657\n",
      "  -3.46558864   8.02803557   5.78167598   3.44711967   6.74178157\n",
      "   0.84360277 -14.45507104  -6.61429413  -1.95167552 -10.65642985\n",
      "  -6.81951703   1.28082668  -0.          25.21814809 -11.23446494\n",
      "   0.           6.25903156  29.31310498  -6.71016332  10.01766185\n",
      "  15.57109719  -9.23994507  -0.89303466   4.81519037  -1.5623813\n",
      "  11.55853264  -9.16484454 -14.35870163 -10.31689509]\n",
      "Intercept: 12.983973925018406\n",
      "Mean squared error:  128914.81129061665\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Lasso(alpha=1.0)\n",
    "# fit model\n",
    "model.fit(x, y)\n",
    "# make a prediction\n",
    "yhat = model.predict(x)\n",
    "# model evaluation\n",
    "mse = mean_squared_error(y, y_predicted)\n",
    "\n",
    "# printing values\n",
    "print(\"Lasso Regression\")\n",
    "print('Slope:' ,model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Mean squared error: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate 10 synthetic datasets with 1000 data points and 100 features where the number of informative features should vary from 10 to 100 by step size 10.\n",
    "#### a. Implement Linear Regression on each generated synthetic datasets and find Mean Square Error(MSE).\n",
    "#### Note : Write down your observation on how MSE changes with each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informative_features_list = [x for x in range(10,101,10)]\n",
    "informative_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 10 Informative Features\n",
      "Mean squared error:  1.9217335376651925e-25\n",
      "\n",
      "Dataset with 20 Informative Features\n",
      "Mean squared error:  3.188741439693426e-25\n",
      "\n",
      "Dataset with 30 Informative Features\n",
      "Mean squared error:  4.43745421568628e-25\n",
      "\n",
      "Dataset with 40 Informative Features\n",
      "Mean squared error:  8.895066446519162e-25\n",
      "\n",
      "Dataset with 50 Informative Features\n",
      "Mean squared error:  1.5406273303135607e-24\n",
      "\n",
      "Dataset with 60 Informative Features\n",
      "Mean squared error:  1.3937219742821182e-24\n",
      "\n",
      "Dataset with 70 Informative Features\n",
      "Mean squared error:  1.2766404494334898e-24\n",
      "\n",
      "Dataset with 80 Informative Features\n",
      "Mean squared error:  1.744188791140023e-24\n",
      "\n",
      "Dataset with 90 Informative Features\n",
      "Mean squared error:  1.3549365285037295e-24\n",
      "\n",
      "Dataset with 100 Informative Features\n",
      "Mean squared error:  1.7677621637985616e-24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for informative_features in informative_features_list:\n",
    "    x,y = datasets.make_regression(n_samples=1000, n_features=100, n_informative=informative_features) \n",
    "    \n",
    "    # Model initialization\n",
    "    regression_model = LinearRegression()\n",
    "    # Fit the data(train the model)\n",
    "    regression_model.fit(x, y)\n",
    "    # Predict\n",
    "    y_predicted = regression_model.predict(x)\n",
    "\n",
    "    # model evaluation\n",
    "    mse = mean_squared_error(y, y_predicted)\n",
    "    r2 = r2_score(y, y_predicted)\n",
    "\n",
    "    # printing values\n",
    "    print(f\"Dataset with {informative_features} Informative Features\")\n",
    "    print('Mean squared error: ', mse)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    For less number of informative features mean squared error is more.from 10 to 40 informative features,\n",
    "    mean squared error is increased.after 50 to 100,mean squared error is less and all are nearly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
